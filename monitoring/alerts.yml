# Prometheus Alert Rules for Zero World
# Critical alerts for global-scale operations

groups:
  # ============================================
  # CRITICAL ALERTS (Immediate Action Required)
  # ============================================
  - name: critical_alerts
    interval: 30s
    rules:
      - alert: ServiceDown
        expr: up{job=~".*-service"} == 0
        for: 1m
        labels:
          severity: critical
          team: platform
        annotations:
          summary: "Service {{ $labels.job }} is down"
          description: "{{ $labels.job }} has been down for more than 1 minute. Immediate action required!"
          runbook: "https://docs.zeroworld.com/runbooks/service-down"

      - alert: HighErrorRate
        expr: |
          sum(rate(http_requests_total{status=~"5.."}[5m])) by (service) 
          / 
          sum(rate(http_requests_total[5m])) by (service) 
          > 0.05
        for: 2m
        labels:
          severity: critical
          team: platform
        annotations:
          summary: "High error rate on {{ $labels.service }}"
          description: "{{ $labels.service }} error rate is {{ $value | humanizePercentage }}. P0 incident!"

      - alert: DatabaseConnectionFailure
        expr: mongodb_up == 0 or redis_up == 0
        for: 30s
        labels:
          severity: critical
          team: database
        annotations:
          summary: "Database connection failure"
          description: "Cannot connect to {{ $labels.database }}. Data layer is compromised!"

      - alert: PaymentServiceDown
        expr: up{job="payment-service"} == 0
        for: 30s
        labels:
          severity: critical
          team: payments
          pagerduty: "yes"
        annotations:
          summary: "CRITICAL: Payment service is down!"
          description: "Payment processing is unavailable. Revenue impact immediate!"

  # ============================================
  # HIGH PRIORITY ALERTS
  # ============================================
  - name: high_priority_alerts
    interval: 60s
    rules:
      - alert: HighLatency
        expr: |
          histogram_quantile(0.95, 
            sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service)
          ) > 1
        for: 5m
        labels:
          severity: high
          team: platform
        annotations:
          summary: "High latency on {{ $labels.service }}"
          description: "P95 latency is {{ $value }}s on {{ $labels.service }}"

      - alert: HighMemoryUsage
        expr: |
          (container_memory_usage_bytes / container_spec_memory_limit_bytes) * 100 > 85
        for: 5m
        labels:
          severity: high
          team: platform
        annotations:
          summary: "High memory usage: {{ $labels.pod }}"
          description: "Memory usage is {{ $value | humanize }}% on {{ $labels.pod }}"

      - alert: HighCPUUsage
        expr: |
          (rate(container_cpu_usage_seconds_total[5m]) * 100) > 80
        for: 5m
        labels:
          severity: high
          team: platform
        annotations:
          summary: "High CPU usage: {{ $labels.pod }}"
          description: "CPU usage is {{ $value | humanize }}% on {{ $labels.pod }}"

      - alert: DiskSpaceRunningOut
        expr: |
          (node_filesystem_avail_bytes / node_filesystem_size_bytes) * 100 < 15
        for: 10m
        labels:
          severity: high
          team: infrastructure
        annotations:
          summary: "Disk space running out on {{ $labels.instance }}"
          description: "Only {{ $value | humanize }}% disk space remaining"

  # ============================================
  # BUSINESS METRICS ALERTS
  # ============================================
  - name: business_alerts
    interval: 300s
    rules:
      - alert: LowUserRegistrations
        expr: |
          rate(user_registrations_total[1h]) < 100
        for: 30m
        labels:
          severity: medium
          team: growth
        annotations:
          summary: "User registration rate dropped"
          description: "Only {{ $value }} registrations per second in last hour"

      - alert: HighPaymentFailureRate
        expr: |
          sum(rate(payment_failures_total[15m])) 
          / 
          sum(rate(payment_attempts_total[15m])) 
          > 0.10
        for: 10m
        labels:
          severity: high
          team: payments
        annotations:
          summary: "High payment failure rate"
          description: "Payment failure rate is {{ $value | humanizePercentage }}"

      - alert: LowDailyActiveUsers
        expr: daily_active_users < 100000
        for: 1h
        labels:
          severity: medium
          team: product
        annotations:
          summary: "DAU dropped below threshold"
          description: "Current DAU: {{ $value | humanize }}"

  # ============================================
  # PERFORMANCE ALERTS
  # ============================================
  - name: performance_alerts
    interval: 120s
    rules:
      - alert: SlowDatabaseQueries
        expr: |
          histogram_quantile(0.95,
            sum(rate(mongodb_query_duration_seconds_bucket[5m])) by (le, collection)
          ) > 0.5
        for: 10m
        labels:
          severity: medium
          team: database
        annotations:
          summary: "Slow queries on {{ $labels.collection }}"
          description: "P95 query time: {{ $value }}s on {{ $labels.collection }}"

      - alert: HighCacheHitRateLow
        expr: |
          (redis_hits / (redis_hits + redis_misses)) * 100 < 80
        for: 15m
        labels:
          severity: medium
          team: platform
        annotations:
          summary: "Low cache hit rate"
          description: "Cache hit rate is {{ $value | humanize }}%"

      - alert: APIRateLimitHit
        expr: |
          rate(rate_limit_exceeded_total[5m]) > 100
        for: 5m
        labels:
          severity: medium
          team: platform
        annotations:
          summary: "Rate limit frequently exceeded"
          description: "{{ $value }} rate limit hits per second"

  # ============================================
  # CAPACITY PLANNING ALERTS
  # ============================================
  - name: capacity_alerts
    interval: 300s
    rules:
      - alert: PodCPUThrottling
        expr: |
          rate(container_cpu_cfs_throttled_seconds_total[5m]) > 0.3
        for: 15m
        labels:
          severity: medium
          team: platform
        annotations:
          summary: "Pod CPU throttling: {{ $labels.pod }}"
          description: "Pod is being throttled {{ $value | humanize }}% of the time"

      - alert: HighPodRestartRate
        expr: |
          rate(kube_pod_container_status_restarts_total[15m]) > 0.1
        for: 10m
        labels:
          severity: medium
          team: platform
        annotations:
          summary: "High pod restart rate: {{ $labels.pod }}"
          description: "Pod restarting {{ $value }} times per minute"

      - alert: HorizontalPodAutoscalerAtMax
        expr: |
          kube_horizontalpodautoscaler_status_current_replicas 
          == 
          kube_horizontalpodautoscaler_spec_max_replicas
        for: 30m
        labels:
          severity: medium
          team: platform
        annotations:
          summary: "HPA at maximum: {{ $labels.hpa }}"
          description: "Consider increasing max replicas for {{ $labels.hpa }}"

  # ============================================
  # SECURITY ALERTS
  # ============================================
  - name: security_alerts
    interval: 60s
    rules:
      - alert: UnauthorizedAccessAttempts
        expr: |
          rate(http_requests_total{status="401"}[5m]) > 50
        for: 2m
        labels:
          severity: high
          team: security
        annotations:
          summary: "High rate of unauthorized access attempts"
          description: "{{ $value }} unauthorized requests per second"

      - alert: SuspiciousTrafficPattern
        expr: |
          rate(http_requests_total[1m]) > 10000
        for: 2m
        labels:
          severity: high
          team: security
        annotations:
          summary: "Possible DDoS attack detected"
          description: "Abnormally high traffic: {{ $value }} req/s from {{ $labels.source_ip }}"

      - alert: SSLCertificateExpiringSoon
        expr: |
          probe_ssl_earliest_cert_expiry - time() < 86400 * 7
        for: 1h
        labels:
          severity: high
          team: infrastructure
        annotations:
          summary: "SSL certificate expiring soon"
          description: "Certificate for {{ $labels.instance }} expires in {{ $value | humanizeDuration }}"

  # ============================================
  # DEPENDENCY ALERTS
  # ============================================
  - name: dependency_alerts
    interval: 120s
    rules:
      - alert: ThirdPartyAPIDown
        expr: probe_success{job="blackbox-http"} == 0
        for: 5m
        labels:
          severity: medium
          team: platform
        annotations:
          summary: "Third-party API unreachable: {{ $labels.instance }}"
          description: "Cannot reach {{ $labels.instance }} for 5 minutes"

      - alert: MessageQueueLag
        expr: |
          rabbitmq_queue_messages_unacknowledged > 10000
        for: 10m
        labels:
          severity: high
          team: platform
        annotations:
          summary: "High message queue lag"
          description: "{{ $value }} unacknowledged messages in {{ $labels.queue }}"

  # ============================================
  # DATA INTEGRITY ALERTS
  # ============================================
  - name: data_integrity_alerts
    interval: 300s
    rules:
      - alert: DatabaseReplicationLag
        expr: mongodb_replication_lag_seconds > 30
        for: 5m
        labels:
          severity: high
          team: database
        annotations:
          summary: "Database replication lag detected"
          description: "Replication lag is {{ $value }}s on {{ $labels.replica }}"

      - alert: BackupFailure
        expr: |
          time() - last_backup_timestamp_seconds > 86400
        for: 1h
        labels:
          severity: critical
          team: database
        annotations:
          summary: "Database backup not completed in 24 hours"
          description: "Last backup was {{ $value | humanizeDuration }} ago"
